
from package_utils.locale.base import Locale

locale_name = "en-us"
locale_display_name = "English (US)"

class _Locale(Locale):
    unknown_model_type_tip = "Unknown model type, please select manually"
    class device_chooser(Locale.device_chooser):
        device_dropdown_label = "Device"
    
    class model_chooser(Locale.model_chooser):
        submit_btn_value = "Select Model"
        model_type_dropdown_label = "Model Type"
        search_path_label = "Search Path"
        workdir_name = "Working Directory"
        archieve_dir_name = "Archived Training"
        models_dir_name = "Models Folder"
        no_model_value = "No Model"
        unuse_value = "Do Not Use"
        no_spk_value = "No Speaker"
        choose_model_dropdown_prefix = "Choose Model"
        refresh_btn_value = "Refresh Options"
        spk_dropdown_label = "Select Speaker"
        no_spk_option = "No Model Loaded"
    
    class form(Locale.form):
        submit_btn_value = "Submit"
        audio_output_1 = "Output Result"
        audio_output_2 = "Output Result/Accompaniment"
        textbox_output = "Output Result"
        dorpdown_liked_checkbox_yes = "Yes"
        dorpdown_liked_checkbox_no = "No"
    
    class model_manager(Locale.model_manager):
        pack_btn_value = "Pack Model"
        pack_result_label = "Pack Result"
        packing_tip = "Packing, please do not click multiple times"
        unpackable_tip = "This model does not support packing"
        clean_log_btn_value = "Clear Log (Clear only if no longer training)"
        change_model_type_info = """
    
        
            
                
                    
                            #### Change Model Type
                            Use only if the model type cannot be recognized! This is not for converting the model type! It's for changing the recognized model type!
                            
                    
                
            
        
    """
        change_model_type_btn_value = "Confirm Change"
        change_success_tip = "Change Successful"
        change_fail_tip = "Change Failed"
    
    class main_ui(Locale.main_ui):
        release_memory_btn_value = "Try to Release VRAM/Memory"
        released_tip = "Attempted to release VRAM/Memory"
        infer_tab = "ğŸ’¡Inference"
        preprocess_tab = "â³Data Processing"
        train_tab = "ğŸ‹ï¸â€â™‚ï¸Training"
        tools_tab = "ğŸ› ï¸Tools"
        settings_tab = "ğŸª¡Settings"
        model_manager_tab = "Model Management"
        install_model_tab = "Install Model"
        fish_audio_preprocess_tab = "Simple Audio Processing"
        vocal_remove_tab = "Vocal Removal"
        detect_spk_tip = "Detected Characters:"
        spk_not_found_tip = "No Characters Detected"
    
    class preprocess(Locale.preprocess):
        tip = """
    
        
            
                
                    
                                Please put your dataset (a bunch of `.wav` files) into the `dataset_raw/Your Character Name` folder under the integration package
                    
                                You can train multiple characters at the same time by creating multiple character folders
                    
                                Once placed, your directory should look like this:
                    
                                ```
                                dataset_raw/
                                |-Your Character Name1/
                                |  | 1.wav
                                |  | 2.wav
                                |  | 3.wav
                                |  ...
                                |-Your Character Name2/
                                |  | 1.wav
                                |  | 2.wav
                                |  | 3.wav
                                |  ...
                                ```
                    
                                If you don't understand anything, just click the button below for automatic data processing
                    
                                If you understand the parameters, you can switch to manual mode for more detailed data processing
                                
                                **CPU users, please use FCPE as the F0 extractor/predictor**
                            
                    
                
            
        
    """
        little_vram_tip = """
    
        
            
                
                    
                                ## The current device does not have a GPU with more than 6GB of VRAM, only training DDSP models is recommended
                            
                    
                
            
        
    """
        open_dataset_folder_btn_value = "Open Dataset Folder"
        choose_model_label = "Choose Model"
    
    class train(Locale.train):
        current_train_model_label = "Current Training Model"
        fouzu_tip = "This is the Buddha from Buddhist culture who can bless your AI training smoothly."
        gd_plus_1 = "Click to Add Merit"
        gd_plus_1_tip = "Merit +1, Furnace Explosion -1"
        choose_sub_model_label = "Choose Sub Model"
        archieve_btn_value = "Archive Working Directory"
        stop_btn_value = "Stop Training"
        archieving_tip = "Archiving, please do not click multiple times"
        archieved_tip = "Archiving Complete, please check the opened folder"
        stopped_tip = "Stop training command sent, please check the training window"
        tensorboard_btn = "å¯åŠ¨ Tensorboard"
        launching_tb_tip = "æ­£åœ¨å¯åŠ¨ Tensorboardï¼Œè¯·ç¨å"
        launched_tb_tip = "Tensorboard å·²åœ¨ {1} å¼€æ”¾"
    
    class settings(Locale.settings):
        page = "Page"
        pkg_settings_label = "Integration Package Settings"
        sovits_settings_label = "SoVITS Settings"
        class pkg(Locale.settings.pkg):
            lang_label = "Language"
            lang_info = "Changing the language requires restarting the integration package"
        
        class sovits(Locale.settings.sovits):
            resolve_port_clash_label = "Attempt to Resolve Port Conflict Issues"
        
        saved_tip = "Saved"
        ddsp6_settings_label = "DDSP-SVC 6 è®¾ç½®"
        class ddsp6(Locale.settings.ddsp6):
            pretrained_model_preference_dropdown_label = "åº•æ¨¡åå¥½"
            default_pretrained_model = "é»˜è®¤åº•æ¨¡ 512 x 6"
            large_pretrained_model = "å¤§ç½‘ç»œåº•æ¨¡ 1024 x 6"
        
    
    class install_model(Locale.install_model):
        tip = """
    
        
            
                
                    
                            ## Currently only supports uploading .sf_pkg/.h0_ddsp_pkg_model format model packages
                            
                    
                
            
        
    """
        file_label = "Upload Model Package"
        model_name_label = "Model Name"
        model_name_placeholder = "Enter Model Name"
        submit_btn_value = "Install Model"
    
    class path_chooser(Locale.path_chooser):
        input_path_label = "Input Folder"
        output_path_label = "Output Folder"
    
    class fish_audio_preprocess(Locale.fish_audio_preprocess):
        to_wav_tab = "Batch to WAV"
        slice_audio_tab = "Audio Slicing"
        preprocess_tab = "Data Processing"
        max_duration_label = "Max Duration"
        submit_btn_value = "Start"
        input_path_not_exist_tip = "Input path does not exist"
    
    class vocal_remove(Locale.vocal_remove):
        input_audio_label = "Input Audio"
        submit_btn_value = "Start"
        vocal_label = "Output - Vocal"
        inst_label = "Output - Accompaniment"
    
    class common_infer(Locale.common_infer):
        audio_label = "Audio File"
        use_vocal_remove_label = "Remove Accompaniment"
        use_vocal_remove_info = "Whether to remove accompaniment"
        f0_label = "F0 Extractor"
        f0_info = "Model for pitch extraction/prediction"
        keychange_label = "Pitch Shift"
        keychange_info = "Reference: male to female 12, female to male -12, adjust this if the timbre is not right"
        threshold_label = "Slicing Threshold"
        threshold_info = "Slicing threshold for vocals, adjust to -40 or higher if there is background noise"
        use_harmony_remove_label = "å»é™¤å’Œå£°"
        use_harmony_remove_info = "æ˜¯å¦å»é™¤å’Œå£°ï¼ˆå¿…é¡»å…ˆå‹¾é€‰ç§»é™¤ä¼´å¥ï¼‰"
    
    class diff_based_infer(Locale.diff_based_infer):
        method_label = "Sampler"
        method_info = "Sampler for reflow"
        infer_step_label = "Inference Steps"
        infer_step_info = "Inference steps, default is fine"
        t_start_label = "T Start"
        t_start_info = "Unknown"
    
    class diff_based_preprocess(Locale.diff_based_preprocess):
        method_label = "F0 Extractor"
        method_info = "Sampler for reflow"
    
    class common_preprocess(Locale.common_preprocess):
        encoder_label = "Voice Encoder"
        encoder_info = "Model for encoding voice"
        f0_label = "F0 Extractor"
        f0_info = "Model for pitch extraction/prediction"
    
    class sovits(Locale.sovits):
        dataset_not_complete_tip = "Dataset incomplete, please check the dataset or reprocess"
        finished = "Finished"
        class infer(Locale.sovits.infer):
            cluster_infer_ratio_label = "Cluster/Feature Ratio"
            cluster_infer_ratio_info = "Ratio of clustering/features, range 0-1, if no clustering model or feature retrieval is trained, default is 0"
            linear_gradient_info = "Crossfade length between two audio slices"
            linear_gradient_label = "Fade Length"
            k_step_label = "Diffusion Steps"
            k_step_info = "The larger the number, the closer to the result of the diffusion model, default is 100"
            enhancer_adaptive_key_label = "Enhancer Adaptive"
            enhancer_adaptive_key_info = "Make the enhancer adapt to higher pitches (unit is semitones), default is 0"
            f0_filter_threshold_label = "F0 Filter Threshold"
            f0_filter_threshold_info = "Effective only when using crepe. Range from 0-1. Lowering this value reduces the probability of pitch deviation but increases mute sounds"
            audio_predict_f0_label = "Automatic F0 Prediction"
            audio_predict_f0_info = "Automatic pitch prediction for voice conversion, do not enable this when converting singing voices as it will cause serious pitch deviations"
            second_encoding_label = "Secondary Encoding"
            second_encoding_info = "The original audio will be re-encoded before shallow diffusion, an occult option that sometimes works well and sometimes poorly"
            clip_label = "Force Slice Length"
            clip_info = "Force audio slice length, 0 means no force"
        
        class preprocess(Locale.sovits.preprocess):
            use_diff_label = "Train Shallow Diffusion"
            use_diff_info = "Check this to generate files needed for training shallow diffusion, will be slower than not checking"
            vol_aug_label = "Loudness Embedding"
            vol_aug_info = "Check this to use loudness embedding"
            num_workers_label = "Number of Processes"
            num_workers_info = "Theoretically the larger the faster"
            subprocess_num_workers_label = "Threads per Process"
            subprocess_num_workers_info = "Theoretically the larger the faster"
            debug_label = "æ˜¯å¦å¼€å¯ Debug æ¨¡å¼"
            debug_info = "å¼€å¯åä¼šè¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼Œéç‰¹æ®Šæƒ…å†µæ²¡å¿…è¦å¼€"
        
        class model_types(Locale.sovits.model_types):
            main = "Main Model"
            diff = "Shallow Diffusion"
            cluster = "Clustering/Retrieval Model"
        
        class model_chooser_extra(Locale.sovits.model_chooser_extra):
            enhance_label = "NSFHifigan Audio Enhancement"
            enhance_info = "Provides certain audio quality enhancement for some models with less training data, but has a negative effect on well-trained models"
            feature_retrieval_label = "Enable Feature Extraction"
            feature_retrieval_info = "Whether to use feature retrieval, will be disabled if using clustering model"
        
        class train_main(Locale.sovits.train_main):
            log_interval_label = "æ—¥å¿—é—´éš”"
            log_interval_info = "æ¯ N æ­¥è¾“å‡ºä¸€æ¬¡æ—¥å¿—"
            eval_interval_label = "éªŒè¯é—´éš”"
            eval_interval_info = "æ¯ N æ­¥ä¿å­˜ä¸€æ¬¡å¹¶éªŒè¯"
            all_in_mem_label = "ç¼“å­˜å…¨æ•°æ®é›†"
            all_in_mem_info = "å°†æ‰€æœ‰æ•°æ®é›†åŠ è½½åˆ°å†…å­˜ä¸­è®­ç»ƒï¼Œä¼šåŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½†æ˜¯éœ€è¦è¶³å¤Ÿçš„å†…å­˜"
            keep_ckpts_label = "ä¿ç•™æ£€æŸ¥ç‚¹"
            keep_ckpts_info = "ä¿ç•™æœ€è¿‘ N ä¸ªæ£€æŸ¥ç‚¹"
            batch_size_label = "è®­ç»ƒæ‰¹æ¬¡å¤§å°"
            batch_size_info = "è¶Šå¤§è¶Šå¥½ï¼Œè¶Šå¤§è¶Šå æ˜¾å­˜"
            learning_rate_label = "å­¦ä¹ ç‡"
            learning_rate_info = "å­¦ä¹ ç‡"
            num_workers_label = "æ•°æ®åŠ è½½å™¨è¿›ç¨‹æ•°"
            num_workers_info = "ä»…åœ¨ CPU æ ¸å¿ƒæ•°å¤§äº 4 æ—¶å¯ç”¨ï¼Œéµå¾ªå¤§å°±æ˜¯å¥½åŸåˆ™"
            half_type_label = "ç²¾åº¦"
            half_type_info = "é€‰æ‹© fp16 å¯ä»¥è·å¾—æ›´å¿«çš„é€Ÿåº¦ï¼Œä½†æ˜¯ç‚¸ç‚‰æ¦‚ç‡ up up"
        
        class train_diff(Locale.sovits.train_diff):
            batchsize_label = "è®­ç»ƒæ‰¹æ¬¡å¤§å°"
            batchsize_info = "è¶Šå¤§è¶Šå¥½ï¼Œè¶Šå¤§è¶Šå æ˜¾å­˜ï¼Œæ³¨æ„ä¸èƒ½è¶…è¿‡è®­ç»ƒé›†æ¡æ•°"
            num_workers_label = "è®­ç»ƒè¿›ç¨‹æ•°"
            num_workers_info = "å¦‚æœä½ æ˜¾å¡æŒºå¥½ï¼Œå¯ä»¥è®¾ä¸º 0"
            amp_dtype_label = "è®­ç»ƒç²¾åº¦"
            amp_dtype_info = "é€‰æ‹© fp16ã€bf16 å¯ä»¥è·å¾—æ›´å¿«çš„é€Ÿåº¦ï¼Œä½†æ˜¯ç‚¸ç‚‰æ¦‚ç‡ up up"
            lr_label = "å­¦ä¹ ç‡"
            lr_info = "ä¸å»ºè®®åŠ¨"
            interval_val_label = "éªŒè¯é—´éš”"
            interval_val_info = "æ¯ N æ­¥éªŒè¯ä¸€æ¬¡ï¼ŒåŒæ—¶ä¿å­˜"
            interval_log_label = "æ—¥å¿—é—´éš”"
            interval_log_info = "æ¯ N æ­¥è¾“å‡ºä¸€æ¬¡æ—¥å¿—"
            interval_force_save_label = "å¼ºåˆ¶ä¿å­˜æ¨¡å‹é—´éš”"
            interval_force_save_info = "æ¯ N æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹"
            gamma_label = "lr è¡°å‡åŠ›åº¦"
            gamma_info = "ä¸å»ºè®®åŠ¨"
            cache_device_label = "ç¼“å­˜è®¾å¤‡"
            cache_device_info = "é€‰æ‹© cuda å¯ä»¥è·å¾—æ›´å¿«çš„é€Ÿåº¦ï¼Œä½†æ˜¯éœ€è¦æ›´å¤§æ˜¾å­˜çš„æ˜¾å¡ (SoVITS ä¸»æ¨¡å‹æ— æ•ˆ)"
            cache_all_data_label = "ç¼“å­˜æ‰€æœ‰æ•°æ®"
            cache_all_data_info = "å¯ä»¥è·å¾—æ›´å¿«çš„é€Ÿåº¦ï¼Œä½†æ˜¯éœ€è¦å¤§å†…å­˜/æ˜¾å­˜çš„è®¾å¤‡"
            epochs_label = "æœ€å¤§è®­ç»ƒè½®æ•°"
            epochs_info = "è¾¾åˆ°è®¾å®šå€¼æ—¶å°†ä¼šåœæ­¢è®­ç»ƒ"
            use_pretrain_label = "ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹"
            use_pretrain_info = "å‹¾é€‰å¯ä»¥å¤§å¹…å‡å°‘è®­ç»ƒæ—¶é—´ï¼Œå¦‚æœä½ ä¸æ‡‚ï¼Œä¸è¦åŠ¨"
        
        class train_cluster(Locale.sovits.train_cluster):
            cluster_or_index_label = "èšç±»æˆ–æ£€ç´¢"
            cluster_or_index_info = "è¦è®­ç»ƒèšç±»è¿˜æ˜¯æ£€ç´¢æ¨¡å‹ï¼Œæ£€ç´¢å’¬å­—æ¯”èšç±»ç¨å¥½"
            use_gpu_label = "ä½¿ç”¨ GPU"
            use_gpu_info = "ä½¿ç”¨ GPU å¯ä»¥åŠ é€Ÿè®­ç»ƒï¼Œè¯¥å‚æ•°åªèšç±»å¯ç”¨"
        
    
    class ddsp6(Locale.ddsp6):
        infer_tip = "Inference DDSP Model"
        class model_types(Locale.ddsp6.model_types):
            cascade = "Cascade Model"
        
        class train(Locale.ddsp6.train):
            batch_size_label = "Training Batch Size"
            batch_size_info = "The larger the better, the larger the more VRAM required, ensure it does not exceed the number of training sets"
            num_workers_label = "Training Processes"
            num_workers_info = "If your GPU is good, set to 0"
            amp_dtype_label = "Training Precision"
            amp_dtype_info = "Selecting fp16 or bf16 can achieve faster speed but increases the probability of crashes"
            lr_label = "Learning Rate"
            lr_info = "Not recommended to change"
            interval_val_label = "Validation Interval"
            interval_val_info = "Validate every N steps, and save"
            interval_log_label = "Log Interval"
            interval_log_info = "Output log every N steps"
            interval_force_save_label = "Force Save Model Interval"
            interval_force_save_info = "Save model every N steps"
            gamma_label = "LR Decay Strength"
            gamma_info = "Not recommended to change"
            cache_device_label = "Cache Device"
            cache_device_info = "Selecting cuda can achieve faster speed but requires larger VRAM (Invalid for SoVITS main model)"
            cache_all_data_label = "Cache All Data"
            cache_all_data_info = "Can achieve faster speed but requires devices with large memory/VRAM"
            epochs_label = "Max Training Epochs"
            epochs_info = "Will stop training when reaching the set value"
            use_pretrain_label = "Use Pretrained Model"
            use_pretrain_info = "Checking this can greatly reduce training time, if you don't understand, don't touch"
        
    
    class reflow(Locale.reflow):
        infer_tip = "Inference ReflowVAESVC Model"
        class train(Locale.reflow.train):
            batch_size_label = "Training Batch Size"
            batch_size_info = "The larger the better, the larger the more VRAM required, ensure it does not exceed the number of training sets"
            num_workers_label = "Training Processes"
            num_workers_info = "If your GPU is good, set to 0"
            amp_dtype_label = "Training Precision"
            amp_dtype_info = "Selecting fp16 or bf16 can achieve faster speed but increases the probability of crashes"
            lr_label = "Learning Rate"
            lr_info = "Not recommended to change"
            interval_val_label = "Validation Interval"
            interval_val_info = "Validate every N steps, and save"
            interval_log_label = "Log Interval"
            interval_log_info = "Output log every N steps"
            interval_force_save_label = "Force Save Model Interval"
            interval_force_save_info = "Save model every N steps"
            gamma_label = "LR Decay Strength"
            gamma_info = "Not recommended to change"
            cache_device_label = "Cache Device"
            cache_device_info = "Selecting cuda can achieve faster speed but requires larger VRAM (Invalid for SoVITS main model)"
            cache_all_data_label = "Cache All Data"
            cache_all_data_info = "Can achieve faster speed but requires devices with large memory/VRAM"
            epochs_label = "Max Training Epochs"
            epochs_info = "Will stop training when reaching the set value"
            use_pretrain_label = "Use Pretrained Model"
            use_pretrain_info = "Checking this can greatly reduce training time, if you don't understand, don't touch"
        
        class model_types(Locale.reflow.model_types):
            cascade = "Cascade Model"
        
    
    default_spk_name = "Default Speaker"
    preprocess_draw_desc = "Divide Validation Set"
    preprocess_desc = "Preprocess (see progress in terminal)"
    preprocess_finished = "Preprocessing Complete"
