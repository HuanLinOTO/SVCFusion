
from package_utils.locale.base import Locale

locale_name = "en-us"
locale_display_name = "English (US)"

class _Locale(Locale):
    unknown_model_type_tip = "Unknown model type, please select manually"
    class device_chooser(Locale.device_chooser):
        device_dropdown_label = "Device"
    
    class model_chooser(Locale.model_chooser):
        submit_btn_value = "Select Model"
        model_type_dropdown_label = "Model Type"
        search_path_label = "Search Path"
        workdir_name = "Working Directory"
        archieve_dir_name = "Archived Training"
        models_dir_name = "Models Folder"
        no_model_value = "No Model"
        unuse_value = "Do Not Use"
        no_spk_value = "No Speaker"
        choose_model_dropdown_prefix = "Choose Model"
        refresh_btn_value = "Refresh Options"
        spk_dropdown_label = "Select Speaker"
        no_spk_option = "No Model Loaded"
    
    class form(Locale.form):
        submit_btn_value = "Submit"
        audio_output_1 = "Output Result"
        audio_output_2 = "Output Result/Accompaniment"
        textbox_output = "Output Result"
        dorpdown_liked_checkbox_yes = "Yes"
        dorpdown_liked_checkbox_no = "No"
    
    class model_manager(Locale.model_manager):
        pack_btn_value = "Pack Model"
        pack_result_label = "Pack Result"
        packing_tip = "Packing, please do not click multiple times"
        unpackable_tip = "This model does not support packing"
        clean_log_btn_value = "Clear Log (Clear only if no longer training)"
        change_model_type_info = """
    
        
            
                
                    
                            #### Change Model Type
                            Use only if the model type cannot be recognized! This is not for converting the model type! It's for changing the recognized model type!
                            
                    
                
            
        
    """
        change_model_type_btn_value = "Confirm Change"
        change_success_tip = "Change Successful"
        change_fail_tip = "Change Failed"
    
    class main_ui(Locale.main_ui):
        release_memory_btn_value = "Try to Release VRAM/Memory"
        released_tip = "Attempted to release VRAM/Memory"
        infer_tab = "üí°Inference"
        preprocess_tab = "‚è≥Data Processing"
        train_tab = "üèãÔ∏è‚Äç‚ôÇÔ∏èTraining"
        tools_tab = "üõ†Ô∏èTools"
        settings_tab = "ü™°Settings"
        model_manager_tab = "Model Management"
        install_model_tab = "Install Model"
        fish_audio_preprocess_tab = "Simple Audio Processing"
        vocal_remove_tab = "Vocal Removal"
        detect_spk_tip = "Detected Characters:"
        spk_not_found_tip = "No Characters Detected"
    
    class preprocess(Locale.preprocess):
        tip = """
    
        
            
                
                    
                                Please put your dataset (a bunch of `.wav` files) into the `dataset_raw/Your Character Name` folder under the integration package
                    
                                You can train multiple characters at the same time by creating multiple character folders
                    
                                Once placed, your directory should look like this:
                    
                                ```
                                dataset_raw/
                                |-Your Character Name1/
                                |  | 1.wav
                                |  | 2.wav
                                |  | 3.wav
                                |  ...
                                |-Your Character Name2/
                                |  | 1.wav
                                |  | 2.wav
                                |  | 3.wav
                                |  ...
                                ```
                    
                                If you don't understand anything, just click the button below for automatic data processing
                    
                                If you understand the parameters, you can switch to manual mode for more detailed data processing
                                
                                **CPU users, please use FCPE as the F0 extractor/predictor**
                            
                    
                
            
        
    """
        little_vram_tip = """
    
        
            
                
                    
                                ## The current device does not have a GPU with more than 6GB of VRAM, only training DDSP models is recommended
                            
                    
                
            
        
    """
        open_dataset_folder_btn_value = "Open Dataset Folder"
        choose_model_label = "Choose Model"
    
    class train(Locale.train):
        current_train_model_label = "Current Training Model"
        fouzu_tip = "This is the Buddha from Buddhist culture who can bless your AI training smoothly."
        gd_plus_1 = "Click to Add Merit"
        gd_plus_1_tip = "Merit +1, Furnace Explosion -1"
        choose_sub_model_label = "Choose Sub Model"
        archieve_btn_value = "Archive Working Directory"
        stop_btn_value = "Stop Training"
        archieving_tip = "Archiving, please do not click multiple times"
        archieved_tip = "Archiving Complete, please check the opened folder"
        stopped_tip = "Stop training command sent, please check the training window"
        tensorboard_btn = "ÂêØÂä® Tensorboard"
        launching_tb_tip = "Ê≠£Âú®ÂêØÂä® TensorboardÔºåËØ∑Á®çÂêé"
        launched_tb_tip = "Tensorboard Â∑≤Âú® {1} ÂºÄÊîæ"
    
    class settings(Locale.settings):
        page = "Page"
        pkg_settings_label = "Integration Package Settings"
        sovits_settings_label = "SoVITS Settings"
        class pkg(Locale.settings.pkg):
            lang_label = "Language"
            lang_info = "Changing the language requires restarting the integration package"
        
        class sovits(Locale.settings.sovits):
            resolve_port_clash_label = "Attempt to Resolve Port Conflict Issues"
        
        saved_tip = "Saved"
        ddsp6_settings_label = "DDSP-SVC 6 ËÆæÁΩÆ"
        class ddsp6(Locale.settings.ddsp6):
            pretrained_model_preference_dropdown_label = "Â∫ïÊ®°ÂÅèÂ•Ω"
            default_pretrained_model = "ÈªòËÆ§Â∫ïÊ®° 512 x 6"
            large_pretrained_model = "Â§ßÁΩëÁªúÂ∫ïÊ®° 1024 x 6"
        
    
    class install_model(Locale.install_model):
        tip = """
    
        
            
                
                    
                            ## Currently only supports uploading .sf_pkg/.h0_ddsp_pkg_model format model packages
                            
                    
                
            
        
    """
        file_label = "Upload Model Package"
        model_name_label = "Model Name"
        model_name_placeholder = "Enter Model Name"
        submit_btn_value = "Install Model"
    
    class path_chooser(Locale.path_chooser):
        input_path_label = "Input Folder"
        output_path_label = "Output Folder"
    
    class fish_audio_preprocess(Locale.fish_audio_preprocess):
        to_wav_tab = "Batch to WAV"
        slice_audio_tab = "Audio Slicing"
        preprocess_tab = "Data Processing"
        max_duration_label = "Max Duration"
        submit_btn_value = "Start"
        input_path_not_exist_tip = "Input path does not exist"
    
    class vocal_remove(Locale.vocal_remove):
        input_audio_label = "Input Audio"
        submit_btn_value = "Start"
        vocal_label = "Output - Vocal"
        inst_label = "Output - Accompaniment"
    
    class common_infer(Locale.common_infer):
        audio_label = "Audio File"
        use_vocal_remove_label = "Remove Accompaniment"
        use_vocal_remove_info = "Whether to remove accompaniment"
        f0_label = "F0 Extractor"
        f0_info = "Model for pitch extraction/prediction"
        keychange_label = "Pitch Shift"
        keychange_info = "Reference: male to female 12, female to male -12, adjust this if the timbre is not right"
        threshold_label = "Slicing Threshold"
        threshold_info = "Slicing threshold for vocals, adjust to -40 or higher if there is background noise"
        use_harmony_remove_label = "ÂéªÈô§ÂíåÂ£∞"
        use_harmony_remove_info = "ÊòØÂê¶ÂéªÈô§ÂíåÂ£∞ÔºàÂøÖÈ°ªÂÖàÂãæÈÄâÁßªÈô§‰º¥Â•èÔºâ"
    
    class diff_based_infer(Locale.diff_based_infer):
        method_label = "Sampler"
        method_info = "Sampler for reflow"
        infer_step_label = "Inference Steps"
        infer_step_info = "Inference steps, default is fine"
        t_start_label = "T Start"
        t_start_info = "Unknown"
    
    class diff_based_preprocess(Locale.diff_based_preprocess):
        method_label = "F0 Extractor"
        method_info = "Sampler for reflow"
    
    class common_preprocess(Locale.common_preprocess):
        encoder_label = "Voice Encoder"
        encoder_info = "Model for encoding voice"
        f0_label = "F0 Extractor"
        f0_info = "Model for pitch extraction/prediction"
    
    class sovits(Locale.sovits):
        dataset_not_complete_tip = "Dataset incomplete, please check the dataset or reprocess"
        finished = "Finished"
        class infer(Locale.sovits.infer):
            cluster_infer_ratio_label = "Cluster/Feature Ratio"
            cluster_infer_ratio_info = "Ratio of clustering/features, range 0-1, if no clustering model or feature retrieval is trained, default is 0"
            linear_gradient_info = "Crossfade length between two audio slices"
            linear_gradient_label = "Fade Length"
            k_step_label = "Diffusion Steps"
            k_step_info = "The larger the number, the closer to the result of the diffusion model, default is 100"
            enhancer_adaptive_key_label = "Enhancer Adaptive"
            enhancer_adaptive_key_info = "Make the enhancer adapt to higher pitches (unit is semitones), default is 0"
            f0_filter_threshold_label = "F0 Filter Threshold"
            f0_filter_threshold_info = "Effective only when using crepe. Range from 0-1. Lowering this value reduces the probability of pitch deviation but increases mute sounds"
            audio_predict_f0_label = "Automatic F0 Prediction"
            audio_predict_f0_info = "Automatic pitch prediction for voice conversion, do not enable this when converting singing voices as it will cause serious pitch deviations"
            second_encoding_label = "Secondary Encoding"
            second_encoding_info = "The original audio will be re-encoded before shallow diffusion, an occult option that sometimes works well and sometimes poorly"
            clip_label = "Force Slice Length"
            clip_info = "Force audio slice length, 0 means no force"
        
        class preprocess(Locale.sovits.preprocess):
            use_diff_label = "Train Shallow Diffusion"
            use_diff_info = "Check this to generate files needed for training shallow diffusion, will be slower than not checking"
            vol_aug_label = "Loudness Embedding"
            vol_aug_info = "Check this to use loudness embedding"
            num_workers_label = "Number of Processes"
            num_workers_info = "Theoretically the larger the faster"
            subprocess_num_workers_label = "Threads per Process"
            subprocess_num_workers_info = "Theoretically the larger the faster"
            debug_label = "ÊòØÂê¶ÂºÄÂêØ Debug Ê®°Âºè"
            debug_info = "ÂºÄÂêØÂêé‰ºöËæìÂá∫Ë∞ÉËØï‰ø°ÊÅØÔºåÈùûÁâπÊÆäÊÉÖÂÜµÊ≤°ÂøÖË¶ÅÂºÄ"
        
        class model_types(Locale.sovits.model_types):
            main = "Main Model"
            diff = "Shallow Diffusion"
            cluster = "Clustering/Retrieval Model"
        
        class model_chooser_extra(Locale.sovits.model_chooser_extra):
            enhance_label = "NSFHifigan Audio Enhancement"
            enhance_info = "Provides certain audio quality enhancement for some models with less training data, but has a negative effect on well-trained models"
            feature_retrieval_label = "Enable Feature Extraction"
            feature_retrieval_info = "Whether to use feature retrieval, will be disabled if using clustering model"
        
        class train_main(Locale.sovits.train_main):
            log_interval_label = "Êó•ÂøóÈó¥Èöî"
            log_interval_info = "ÊØè N Ê≠•ËæìÂá∫‰∏ÄÊ¨°Êó•Âøó"
            eval_interval_label = "È™åËØÅÈó¥Èöî"
            eval_interval_info = "ÊØè N Ê≠•‰øùÂ≠ò‰∏ÄÊ¨°Âπ∂È™åËØÅ"
            all_in_mem_label = "ÁºìÂ≠òÂÖ®Êï∞ÊçÆÈõÜ"
            all_in_mem_info = "Â∞ÜÊâÄÊúâÊï∞ÊçÆÈõÜÂä†ËΩΩÂà∞ÂÜÖÂ≠ò‰∏≠ËÆ≠ÁªÉÔºå‰ºöÂä†Âø´ËÆ≠ÁªÉÈÄüÂ∫¶Ôºå‰ΩÜÊòØÈúÄË¶ÅË∂≥Â§üÁöÑÂÜÖÂ≠ò"
            keep_ckpts_label = "‰øùÁïôÊ£ÄÊü•ÁÇπ"
            keep_ckpts_info = "‰øùÁïôÊúÄËøë N ‰∏™Ê£ÄÊü•ÁÇπ"
            batch_size_label = "ËÆ≠ÁªÉÊâπÊ¨°Â§ßÂ∞è"
            batch_size_info = "Ë∂äÂ§ßË∂äÂ•ΩÔºåË∂äÂ§ßË∂äÂç†ÊòæÂ≠ò"
            learning_rate_label = "Â≠¶‰π†Áéá"
            learning_rate_info = "Â≠¶‰π†Áéá"
            num_workers_label = "Êï∞ÊçÆÂä†ËΩΩÂô®ËøõÁ®ãÊï∞"
            num_workers_info = "‰ªÖÂú® CPU Ê†∏ÂøÉÊï∞Â§ß‰∫é 4 Êó∂ÂêØÁî®ÔºåÈÅµÂæ™Â§ßÂ∞±ÊòØÂ•ΩÂéüÂàô"
            half_type_label = "Á≤æÂ∫¶"
            half_type_info = "ÈÄâÊã© fp16 ÂèØ‰ª•Ëé∑ÂæóÊõ¥Âø´ÁöÑÈÄüÂ∫¶Ôºå‰ΩÜÊòØÁÇ∏ÁÇâÊ¶ÇÁéá up up"
        
        class train_diff(Locale.sovits.train_diff):
            batchsize_label = "ËÆ≠ÁªÉÊâπÊ¨°Â§ßÂ∞è"
            batchsize_info = "Ë∂äÂ§ßË∂äÂ•ΩÔºåË∂äÂ§ßË∂äÂç†ÊòæÂ≠òÔºåÊ≥®ÊÑè‰∏çËÉΩË∂ÖËøáËÆ≠ÁªÉÈõÜÊù°Êï∞"
            num_workers_label = "ËÆ≠ÁªÉËøõÁ®ãÊï∞"
            num_workers_info = "Â¶ÇÊûú‰Ω†ÊòæÂç°Êå∫Â•ΩÔºåÂèØ‰ª•ËÆæ‰∏∫ 0"
            amp_dtype_label = "ËÆ≠ÁªÉÁ≤æÂ∫¶"
            amp_dtype_info = "ÈÄâÊã© fp16„ÄÅbf16 ÂèØ‰ª•Ëé∑ÂæóÊõ¥Âø´ÁöÑÈÄüÂ∫¶Ôºå‰ΩÜÊòØÁÇ∏ÁÇâÊ¶ÇÁéá up up"
            lr_label = "Â≠¶‰π†Áéá"
            lr_info = "‰∏çÂª∫ËÆÆÂä®"
            interval_val_label = "È™åËØÅÈó¥Èöî"
            interval_val_info = "ÊØè N Ê≠•È™åËØÅ‰∏ÄÊ¨°ÔºåÂêåÊó∂‰øùÂ≠ò"
            interval_log_label = "Êó•ÂøóÈó¥Èöî"
            interval_log_info = "ÊØè N Ê≠•ËæìÂá∫‰∏ÄÊ¨°Êó•Âøó"
            interval_force_save_label = "Âº∫Âà∂‰øùÂ≠òÊ®°ÂûãÈó¥Èöî"
            interval_force_save_info = "ÊØè N Ê≠•‰øùÂ≠ò‰∏ÄÊ¨°Ê®°Âûã"
            gamma_label = "lr Ë°∞ÂáèÂäõÂ∫¶"
            gamma_info = "‰∏çÂª∫ËÆÆÂä®"
            cache_device_label = "ÁºìÂ≠òËÆæÂ§á"
            cache_device_info = "ÈÄâÊã© cuda ÂèØ‰ª•Ëé∑ÂæóÊõ¥Âø´ÁöÑÈÄüÂ∫¶Ôºå‰ΩÜÊòØÈúÄË¶ÅÊõ¥Â§ßÊòæÂ≠òÁöÑÊòæÂç° (SoVITS ‰∏ªÊ®°ÂûãÊó†Êïà)"
            cache_all_data_label = "ÁºìÂ≠òÊâÄÊúâÊï∞ÊçÆ"
            cache_all_data_info = "ÂèØ‰ª•Ëé∑ÂæóÊõ¥Âø´ÁöÑÈÄüÂ∫¶Ôºå‰ΩÜÊòØÈúÄË¶ÅÂ§ßÂÜÖÂ≠ò/ÊòæÂ≠òÁöÑËÆæÂ§á"
            epochs_label = "ÊúÄÂ§ßËÆ≠ÁªÉËΩÆÊï∞"
            epochs_info = "ËææÂà∞ËÆæÂÆöÂÄºÊó∂Â∞Ü‰ºöÂÅúÊ≠¢ËÆ≠ÁªÉ"
            use_pretrain_label = "‰ΩøÁî®È¢ÑËÆ≠ÁªÉÊ®°Âûã"
            use_pretrain_info = "ÂãæÈÄâÂèØ‰ª•Â§ßÂπÖÂáèÂ∞ëËÆ≠ÁªÉÊó∂Èó¥ÔºåÂ¶ÇÊûú‰Ω†‰∏çÊáÇÔºå‰∏çË¶ÅÂä®"
        
        class train_cluster(Locale.sovits.train_cluster):
            cluster_or_index_label = "ËÅöÁ±ªÊàñÊ£ÄÁ¥¢"
            cluster_or_index_info = "Ë¶ÅËÆ≠ÁªÉËÅöÁ±ªËøòÊòØÊ£ÄÁ¥¢Ê®°ÂûãÔºåÊ£ÄÁ¥¢Âí¨Â≠óÊØîËÅöÁ±ªÁ®çÂ•Ω"
            use_gpu_label = "‰ΩøÁî® GPU"
            use_gpu_info = "‰ΩøÁî® GPU ÂèØ‰ª•Âä†ÈÄüËÆ≠ÁªÉÔºåËØ•ÂèÇÊï∞Âè™ËÅöÁ±ªÂèØÁî®"
        
    
    class ddsp6(Locale.ddsp6):
        infer_tip = "Inference DDSP Model"
        class model_types(Locale.ddsp6.model_types):
            cascade = "Cascade Model"
        
        class train(Locale.ddsp6.train):
            batch_size_label = "Training Batch Size"
            batch_size_info = "The larger the better, the larger the more VRAM required, ensure it does not exceed the number of training sets"
            num_workers_label = "Training Processes"
            num_workers_info = "If your GPU is good, set to 0"
            amp_dtype_label = "Training Precision"
            amp_dtype_info = "Selecting fp16 or bf16 can achieve faster speed but increases the probability of crashes"
            lr_label = "Learning Rate"
            lr_info = "Not recommended to change"
            interval_val_label = "Validation Interval"
            interval_val_info = "Validate every N steps, and save"
            interval_log_label = "Log Interval"
            interval_log_info = "Output log every N steps"
            interval_force_save_label = "Force Save Model Interval"
            interval_force_save_info = "Save model every N steps"
            gamma_label = "LR Decay Strength"
            gamma_info = "Not recommended to change"
            cache_device_label = "Cache Device"
            cache_device_info = "Selecting cuda can achieve faster speed but requires larger VRAM (Invalid for SoVITS main model)"
            cache_all_data_label = "Cache All Data"
            cache_all_data_info = "Can achieve faster speed but requires devices with large memory/VRAM"
            epochs_label = "Max Training Epochs"
            epochs_info = "Will stop training when reaching the set value"
            use_pretrain_label = "Use Pretrained Model"
            use_pretrain_info = "Checking this can greatly reduce training time, if you don't understand, don't touch"
        
    
    class reflow(Locale.reflow):
        infer_tip = "Inference ReflowVAESVC Model"
        class train(Locale.reflow.train):
            batch_size_label = "Training Batch Size"
            batch_size_info = "The larger the better, the larger the more VRAM required, ensure it does not exceed the number of training sets"
            num_workers_label = "Training Processes"
            num_workers_info = "If your GPU is good, set to 0"
            amp_dtype_label = "Training Precision"
            amp_dtype_info = "Selecting fp16 or bf16 can achieve faster speed but increases the probability of crashes"
            lr_label = "Learning Rate"
            lr_info = "Not recommended to change"
            interval_val_label = "Validation Interval"
            interval_val_info = "Validate every N steps, and save"
            interval_log_label = "Log Interval"
            interval_log_info = "Output log every N steps"
            interval_force_save_label = "Force Save Model Interval"
            interval_force_save_info = "Save model every N steps"
            gamma_label = "LR Decay Strength"
            gamma_info = "Not recommended to change"
            cache_device_label = "Cache Device"
            cache_device_info = "Selecting cuda can achieve faster speed but requires larger VRAM (Invalid for SoVITS main model)"
            cache_all_data_label = "Cache All Data"
            cache_all_data_info = "Can achieve faster speed but requires devices with large memory/VRAM"
            epochs_label = "Max Training Epochs"
            epochs_info = "Will stop training when reaching the set value"
            use_pretrain_label = "Use Pretrained Model"
            use_pretrain_info = "Checking this can greatly reduce training time, if you don't understand, don't touch"
        
        class model_types(Locale.reflow.model_types):
            cascade = "Cascade Model"
        
    
    default_spk_name = "Default Speaker"
    preprocess_draw_desc = "Divide Validation Set"
    preprocess_desc = "Preprocess (see progress in terminal)"
    preprocess_finished = "Preprocessing Complete"
